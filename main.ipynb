{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Risk Factors in Cryptocurrency"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Thesis Project\n",
    "\n",
    "<div style=\"text-align: right;font-size: 0.8em\">Document Version 1.0.0</div>\n",
    "\n",
    "This file requires `pandas`, `datetime`, `numpy`, `wand`, `pdf2image`, `Pillow`, and `math` to run. If one of these imports fails, please install the corresponding library and make sure that you have activated the corresponding virtual environment.\n",
    "\n",
    "The project follows closely the methodology proposed by Liu, Tsyvinski, and Wu (2022) in their paper titled [Common Risk Factors in Cryptocurrency](https://onlinelibrary.wiley.com/doi/abs/10.1111/jofi.13119). Researchers and practitioners can use this paper to check the results of the paper and perhaps retrieve an updated version of the basic findings. They can also use it as a toolbox to use for other projects or to run an extended analysis including further risk factors. Finally, asset management firm may use this code to assess the risk of their portfolio or to firm anomalies in the returns of cryptocurrencies.\n",
    "\n",
    "For this analysis, I occasionally had to make assumption, for example, regarding the procedure to convert daily to weekly data. This is especially so because the authors of the paper did not provide a detailed enough description of their decisions. There are other, perhabs better ways of doing certain steps and I am always grateful for any feedback that you might provide.\n",
    "\n",
    "The order of the following sections is closely following the structure of the paper. The outline is:\n",
    "* [I. Data](#I.-Data): The files for all data sources can be found in the data folder. The main blockchain trading data is retrieved from CoinGecko (coingecko_data.py). It is advisable to download the cryptocurrency data set in smaller chunks (for example, 100 cryptocurrencies), since the data set is relatively large and takes long to download due to the API limit. The merge_data.py file can then be used to merge all individal cryptocurrency data files into one large file that is supposed to be loaded into the code below. The daily crptocurrency (aka coin) data is converted to weekly returns using the last available prices: $$r_t = \\frac{p_t-p_{t-1}}{p_{t-1}}$$ One can also compute log-returns instead. The definition of the weeks is as follows: The first 7 days of a given year are the first week. The following 50 weeks consist of 7 days each. The last week has either 8 or 9 days (if the year is a leap year). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     coin_daily_prices \u001b[39m=\u001b[39m coin_daily_trading_data[[\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprice\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmarket_cap\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m     26\u001b[0m     \u001b[39m# now we compute the weekly prices\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[39m# the first column is year/week and the second column is the weekly price\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     coin_weekly_prices \u001b[39m=\u001b[39m cf\u001b[39m.\u001b[39;49mweekly_data(coin_daily_prices, start_date, end_date, download\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     29\u001b[0m     coins_weekly_prices[coin_id] \u001b[39m=\u001b[39m coin_weekly_prices\n\u001b[1;32m     31\u001b[0m \u001b[39m# using the weekly price data to compute the weekly returns\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/Crypto-Currency-Asset-Pricing/convert_frequency.py:63\u001b[0m, in \u001b[0;36mweekly_data\u001b[0;34m(data, start_date, end_date, name, path, download)\u001b[0m\n\u001b[1;32m     61\u001b[0m new_data_row \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m:\u001b[39m0\u001b[39m]\n\u001b[1;32m     62\u001b[0m new_data_row\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39myear/week\u001b[39m\u001b[39m\"\u001b[39m, [])\n\u001b[0;32m---> 63\u001b[0m new_data_row \u001b[39m=\u001b[39m new_data_row\u001b[39m.\u001b[39;49mdrop(\u001b[39m\"\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m\"\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     65\u001b[0m columns \u001b[39m=\u001b[39m new_data_row\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     66\u001b[0m columns\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39myear/week\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas/core/frame.py:5396\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5248\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   5249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   5250\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5257\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5258\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5259\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5260\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5261\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5394\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5395\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5396\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5397\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5398\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5399\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5400\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5401\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5402\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5403\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5404\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas/core/generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas/core/generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas/core/indexes/base.py:6973\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6970\u001b[0m     arr_dtype \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   6971\u001b[0m     labels \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mindex_labels_to_array(labels, dtype\u001b[39m=\u001b[39marr_dtype)\n\u001b[0;32m-> 6973\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_indexer_for(labels)\n\u001b[1;32m   6974\u001b[0m mask \u001b[39m=\u001b[39m indexer \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   6975\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas/core/indexes/base.py:6095\u001b[0m, in \u001b[0;36mIndex.get_indexer_for\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   6077\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6078\u001b[0m \u001b[39mGuaranteed return of an indexer even when non-unique.\u001b[39;00m\n\u001b[1;32m   6079\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6092\u001b[0m \u001b[39marray([0, 2])\u001b[39;00m\n\u001b[1;32m   6093\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6094\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 6095\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_indexer(target)\n\u001b[1;32m   6096\u001b[0m indexer, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_indexer_non_unique(target)\n\u001b[1;32m   6097\u001b[0m \u001b[39mreturn\u001b[39;00m indexer\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas/core/indexes/base.py:3910\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3907\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   3908\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n\u001b[0;32m-> 3910\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_compare(target) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_partial_index(target):\n\u001b[1;32m   3911\u001b[0m     \u001b[39m# IntervalIndex get special treatment bc numeric scalars can be\u001b[39;00m\n\u001b[1;32m   3912\u001b[0m     \u001b[39m#  matched to Interval scalars\u001b[39;00m\n\u001b[1;32m   3913\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_indexer_non_comparable(target, method\u001b[39m=\u001b[39mmethod, unique\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   3915\u001b[0m \u001b[39mif\u001b[39;00m is_categorical_dtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m   3916\u001b[0m     \u001b[39m# _maybe_cast_listlike_indexer ensures target has our dtype\u001b[39;00m\n\u001b[1;32m   3917\u001b[0m     \u001b[39m#  (could improve perf by doing _should_compare check earlier?)\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas/core/indexes/base.py:6335\u001b[0m, in \u001b[0;36mIndex._should_compare\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   6328\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   6329\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_should_compare\u001b[39m(\u001b[39mself\u001b[39m, other: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   6330\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6331\u001b[0m \u001b[39m    Check if `self == other` can ever have non-False entries.\u001b[39;00m\n\u001b[1;32m   6332\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   6334\u001b[0m     \u001b[39mif\u001b[39;00m (other\u001b[39m.\u001b[39mis_boolean() \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_numeric()) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m-> 6335\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mis_boolean() \u001b[39mand\u001b[39;00m other\u001b[39m.\u001b[39mis_numeric()\n\u001b[1;32m   6336\u001b[0m     ):\n\u001b[1;32m   6337\u001b[0m         \u001b[39m# GH#16877 Treat boolean labels passed to a numeric index as not\u001b[39;00m\n\u001b[1;32m   6338\u001b[0m         \u001b[39m#  found. Without this fix False and True would be treated as 0 and 1\u001b[39;00m\n\u001b[1;32m   6339\u001b[0m         \u001b[39m#  respectively.\u001b[39;00m\n\u001b[1;32m   6340\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   6342\u001b[0m     other \u001b[39m=\u001b[39m unpack_nested_dtype(other)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas/core/indexes/base.py:2456\u001b[0m, in \u001b[0;36mIndex.is_boolean\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2422\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   2423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_boolean\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   2424\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2425\u001b[0m \u001b[39m    Check if the Index only consists of booleans.\u001b[39;00m\n\u001b[1;32m   2426\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2454\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m   2455\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minferred_type \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas/core/indexes/base.py:2751\u001b[0m, in \u001b[0;36mIndex.inferred_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[39m@cache_readonly\u001b[39m\n\u001b[1;32m   2747\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minferred_type\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m str_t:\n\u001b[1;32m   2748\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2749\u001b[0m \u001b[39m    Return a string of the type inferred from the values.\u001b[39;00m\n\u001b[1;32m   2750\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2751\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49minfer_dtype(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, skipna\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas/_libs/lib.pyx:1487\u001b[0m, in \u001b[0;36mpandas._libs.lib.infer_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pandas/_libs/lib.pyx:1345\u001b[0m, in \u001b[0;36mpandas._libs.lib._try_infer_map\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/numpy/core/_dtype.py:351\u001b[0m, in \u001b[0;36m_name_get\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m dtype\u001b[39m.\u001b[39misbuiltin \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    348\u001b[0m     \u001b[39m# user dtypes don't promise to do anything special\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     \u001b[39mreturn\u001b[39;00m dtype\u001b[39m.\u001b[39mtype\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m--> 351\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(dtype\u001b[39m.\u001b[39mtype, np\u001b[39m.\u001b[39mvoid):\n\u001b[1;32m    352\u001b[0m     \u001b[39m# historically, void subclasses preserve their name, eg `record64`\u001b[39;00m\n\u001b[1;32m    353\u001b[0m     name \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39mtype\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    354\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd, datetime, numpy as np, math, time, os\n",
    "from wand.image import Image\n",
    "# and other modules from the directory\n",
    "import convert_frequency, render_df, data.coingecko_data as coingecko_data, merge_data\n",
    "\n",
    "# specify the data range for the analysis\n",
    "# in the paper, the authors start on 2014-01-01 due to data availability\n",
    "start_date = \"2014-01-01\"\n",
    "end_date = str(datetime.date.today())\n",
    "\n",
    "# select the path to the directory where you want to store the data\n",
    "data_path = r\"/Users/Marc/Desktop/Past Affairs/Past Universities/SSE Courses/Master Thesis/Data\"\n",
    "\n",
    "# downloading the data from CoinGecko.com and storing it in smaller data subsets at the specified location\n",
    "# the data contains daily prices, market caps, and trading volumes\n",
    "# this step can take up to 2 days due to the API traffic limit\n",
    "if not os.path.exists(data_path + \"/coingecko\"):\n",
    "    coingecko_data.retrieve_data(start_date, end_date, path=data_path)\n",
    "\n",
    "# merging the data subsets and storing the result at the specified location\n",
    "# this step can take up to 12 hours\n",
    "if not os.path.exists(data_path + \"/cg_data.csv\"):\n",
    "    merge_data.merge(start_date, end_date, path=data_path)\n",
    "\n",
    "# the data was retrieved on 2023-01-13\n",
    "daily_trading_data = pd.read_csv(data_path+\"/cg_data.csv\")\n",
    "\n",
    "# all unique coin IDs\n",
    "coin_ids = pd.unique(daily_trading_data[\"id\"])\n",
    "\n",
    "# if the file for weekly data does not already exist\n",
    "if not os.path.exists(data_path + \"/cg_weekly_data.csv\"):\n",
    "    # converting the data subset for every coin into weekly frequency\n",
    "    dfs = []\n",
    "    for coin_id in coin_ids:\n",
    "        # get all the data for one coin\n",
    "        coin_daily_trading_data = daily_trading_data[daily_trading_data[\"id\"] == coin_id]\n",
    "        # now we compute the weekly data\n",
    "        # the first column is year/week and the second column is the weekly price\n",
    "        # the function weekly_data is designed to perform this transformation for a single coin at a time\n",
    "        # this step takes a long time since the data set has a large size\n",
    "        coin_weekly_data = convert_frequency.weekly_data(coin_daily_trading_data, start_date, end_date, download=False)\n",
    "        dfs.append(coin_weekly_data)\n",
    "        \n",
    "    # combining all dataframes in the dfs list\n",
    "    coins_weekly_data = pd.concat(dfs)\n",
    "\n",
    "    coins_weekly_data.to_csv(data_path + \"/cg_weekly_data.csv\", index=False)\n",
    "\n",
    "# next, we need to \"unwrap\" the data again\n",
    "\n",
    "# storing the data in a list with tuples for the ID and the weekly prices (last available prices each week)\n",
    "coins_weekly_prices = {}\n",
    "for coin_id in coin_ids:\n",
    "    # get all the data for one coin\n",
    "    coin_daily_trading_data = daily_trading_data[daily_trading_data[\"id\"] == coin_id]\n",
    "    # we need market_cap to compute the value-weighted market returns\n",
    "    coin_daily_prices = coin_daily_trading_data[[\"date\", \"price\", \"market_cap\"]]\n",
    "    # now we compute the weekly prices\n",
    "    # the first column is year/week and the second column is the weekly price\n",
    "    # this step takes a long time since the data set has a large size\n",
    "    coin_weekly_prices = convert_frequency.weekly_data(coin_daily_prices, start_date, end_date, download=False)\n",
    "    coins_weekly_prices[coin_id] = coin_weekly_prices\n",
    "\n",
    "full_coins_weekly_prices = coins_weekly_prices[coin_ids[0]]\n",
    "\n",
    "[0:0]\n",
    "\n",
    "# downloading the data since the conversion process might also take a long time\n",
    "\n",
    "\n",
    "# using the weekly price data to compute the weekly returns\n",
    "coins_weekly_returns = {}\n",
    "for coin_id in coin_ids:\n",
    "    coin_weekly_prices = coins_weekly_prices[coin_id]\n",
    "    # we are losing the first week, since we do not have a previous week for the first week (first week of 2014)\n",
    "    coin_weekly_returns = [np.nan]\n",
    "    for i in range(len(coin_weekly_prices) - 1):\n",
    "        weekly_return = (coin_weekly_prices[\"price\"][i + 1] - coin_weekly_prices[\"price\"][i]) / coin_weekly_prices[\"price\"][i]\n",
    "        # alternatively, the log-return can be computed as follows (math.log() is the natural logarithm by default):\n",
    "        # weekly_log_return = math.log(coin_weekly_prices[\"price\"][i + 1] / coin_weekly_prices[\"price\"][i])\n",
    "        coin_weekly_returns.append(weekly_return)\n",
    "    # adding the return column to the previous date column\n",
    "    df = coin_weekly_prices[\"year/week\", \"market_cap\"]\n",
    "    df[\"return\"] = coin_weekly_returns\n",
    "    coins_weekly_returns[coin_id] = df\n",
    "    # checking for NaNs\n",
    "    if df[\"return\"].isna().sum() != 0:\n",
    "        print(\"The number of NaNs entries for \" + coin_id + \" is: \" + str(df[\"return\"].isna().sum()))\n",
    "\n",
    "# constructing the cryptocurrency market returns\n",
    "weeks = []\n",
    "market_returns = []\n",
    "included_ids = []\n",
    "# looping through all weeks\n",
    "for week in coins_weekly_returns[coin_ids[0]][\"year/week\"]:\n",
    "    weeks.append(week)\n",
    "    returns = []\n",
    "    market_caps = []\n",
    "    # to keep track of which and how many coins are included for every week\n",
    "    weekly_included_ids = []\n",
    "    for coin_id in coin_ids:\n",
    "        coin_weekly_returns = coins_weekly_returns[coin_id]\n",
    "        coin_weekly_data = coin_weekly_returns[coin_weekly_returns[\"year/week\"] == week]\n",
    "        # ignoring all NaNs\n",
    "        # the most convenient way to check if no cell value are NaN is by applying .isna().sum().sum()\n",
    "        if coin_weekly_data.isna().sum().sum() == 0:\n",
    "            # the ID is included\n",
    "            weekly_included_ids.append(coin_id)\n",
    "            returns.append(coin_weekly_data[\"return\"])\n",
    "            market_caps.append(coin_weekly_data[\"market_cap\"])\n",
    "    # if all returns are NaN (for example, in the first week of the time period considered)\n",
    "    if len(returns) == 0:\n",
    "        # no value is added\n",
    "        market_returns.append(np.nan)\n",
    "        included_ids.append(np.nan)\n",
    "    else:\n",
    "        # for every week add the value-weighted market return (the sumproduct of the returns and the market caps divided by the sum of the market caps) and the included coin IDs\n",
    "        market_returns.append(sum(x * y for x, y in zip(returns, market_caps)) / sum(market_caps))\n",
    "        included_ids.append(weekly_included_ids)\n",
    "market_returns = pd.DataFrame({\"week\": weeks, \"average_return\": market_returns, \"included_ids\": included_ids})\n",
    "\n",
    "print(market_returns.head8)\n",
    "\n",
    "\"\"\"\n",
    "summary_statistics = pd.DataFrame({\"Date\": [\"2014-01-01\", \"2014-01-02\"], \"Price\": [12, 13]})\n",
    "\n",
    "# creates a temporary PDF file named \"cover.pdf\"\n",
    "# repeating the process overwrites the file\n",
    "render_df.render_summary_statistics(summary_statistics)\n",
    "\n",
    "pdf_path = os.getcwd() + \"/cover.pdf\"\n",
    "# printing the PDF\n",
    "# this code has to be in the main file\n",
    "img = Image(filename=pdf_path, resolution=100)\n",
    "img\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74309577635f6089c540d7d4ca5dc414c3665bebb3159a664b0224275d6afd7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
